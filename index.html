<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript"
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">R&B: REGION AND BOUNDARY AWARE ZERO-SHOT
              GROUNDED TEXT-TO-IMAGE GENERATION</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="" target="_blank">Jiayu Xiao</a><sup>1,2*</sup>,</span>
                <span class="author-block">
                  <a href="" target="_blank">Liang Li</a><sup>1*&dagger;</sup>,</span>
                  <span class="author-block">
                    <a href="" target="_blank">Henglei Lv</a><sup>1,2*</sup>,
                  </span>
                  <span class="author-block">
                    <a href="" target="_blank">Shuhui Wang</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="" target="_blank">Qingming Huang</a><sup>3</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Key Lab of Intell. Info. Process., Inst. of Comput. Tech., CAS, Beijing, China</span>
                    <span class="author-block"><sup>2</sup>University of Chinese Academy of Sciences, Beijing, China</span>
                    <span class="author-block"><sup>3</sup>Peng Cheng Laboratory, Shenzhen, China</span>
                    <!-- <span class="author-block"></span> -->
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                    <span class="email-cntrb"><small><br><sup>&dagger; Indicates Corresponding Author</sup></small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2310.08872.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon!)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2310.08872" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- <section class="hero teaser">
  </div>
  Abstract
  </div>
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">

        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->


<!-- Introduction image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/Introduction.png" alt="Intro Image">
      <h2 class="subtitle has-text-centered">
        R&B injects spatial instructions into the denoising process through classifier guidance. And generates images that highly align with the text description and layout instructions without auxiliary training. 
      </h2>
    </div>
  </div>
</section>
<!-- End introduction Image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent text-to-image (T2I) diffusion models have achieved remarkable progress in generating high-quality images given text-prompts as input. However, these models fail to convey appropriate spatial composition specified by a layout instruction. In this work, we probe into zero-shot grounded T2I generation with diffusion models, that is, generating images corresponding to the input layout information without training auxiliary modules or finetuning diffusion models. We propose a Region and Boundary (R&B) aware cross-attention guidance approach that gradually modulates the attention maps of diffusion model during generative process, and assists the model to synthesize images (1) with high fidelity, (2) highly compatible with textual input, and (3) interpreting layout instructions accurately. Specifically, we leverage the discrete sampling to bridge the gap between consecutive attention maps and discrete layout constraints, and design a region-aware loss to refine the generative layout during diffusion process. We further propose a boundary- aware loss to strengthen object discriminability within the corresponding regions. Experimental results show that our method outperforms existing state-of-the-art zero-shot grounded T2I generation methods by a large margin both qualitatively and quantitatively on several benchmarks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Framework -->
<section class="hero teaser is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Framework</h2>
      </div>
      <img src="static/images/method_new.png" alt="Methods">
      <h2 class="subtitle has-text-centered">
        Two loss functions are proposed to modulate the cross-attention of diffusion unet: region-aware loss and boundary-aware loss. Optimizing these two losses helps to correctly incorperate the layout instructions into generative process.
      </h2>
    </div>
  </div>
</section>
<!-- End Framework -->


<!-- Visual comparison -->
<section class="section hero is-light">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Visual comparisons with competing training-free methods</h2>
    </div>
    <div class="container is-max-desktop">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/comp.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Visual comparisons with different baselines across different text prompts
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/supp_comp_1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Visual comparisons with different baselines across different random seeds
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/supp_comp_2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Visual comparisons with different baselines across different random seeds
       </h2>
     </div>
  </div>
</div>
</div>
</section>
<!-- End Visual comparison -->


<!-- Variation image-->
<section class="section hero is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Visual variations across different text and box prompts</h2>
    </div>
    <div class="container is-max-desktop">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/seeds1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Visual variations across different random seeds
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/seeds2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Visual variations across different random seeds
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/seeds3.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Visual variations across different random seeds
       </h2>
     </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/change_obj.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Visual variations across different text prompts
      </h2>
    </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/variation.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Multiple variations of generated images. The shape and localization of boxes are changed for spatial variations. 
          And the instances of text prompts are changed for semantic variations.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End variation image -->

<!-- Quant res -->
<section class="section hero is-light">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Quantitative comparisons</h2>
    </div>
    <div class="container is-max-desktop">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/res1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Quantitative results on HRS and DrawBench, best results are <b>bold</b>
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/res2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Quantitative comparisons of spatial accuracy and text similarity
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- Quant res -->


<!-- Image carousel -->

<!-- End image carousel -->




<!-- Youtube video -->

<!-- End youtube video -->


<!-- Video carousel -->

<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
